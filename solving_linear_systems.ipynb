{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "million-landscape",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, different methods are used to solve the linear system $Ax = b$ where \\\\\n",
    "\n",
    "\\begin{equation*}\n",
    "A = \\begin{bmatrix}\n",
    "0 & 3 & -1 & 8 \\\\\n",
    "-1 & 11 & -1 & 3 \\\\\n",
    "2 & -1 & 10 & - 1 \\\\\n",
    "10 & -1 & 2 & 0\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "b = \\begin{bmatrix}\n",
    "15 \\\\\n",
    "25 \\\\\n",
    "-11 \\\\\n",
    "6\n",
    "\\end{bmatrix}\n",
    "\\end{equation*} \\\\\n",
    "\n",
    "All the methods are implemented from scratch without using any linear algebra package. First, let's import relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "noted-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-solution",
   "metadata": {},
   "source": [
    "Then we create the matrix $A$ and the vector $b$ as numpy arrays. A variable $n$ is created to store the number of rows (and columns as $A$ is a square matrix) of the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deadly-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0., 3., -1., 8.], [-1., 11., -1., 3.], [2., -1., 10., -1.], [10., -1., 2., 0.]]) # matrix\n",
    "b = np.array([15., 25., -11., 6.]) # vector\n",
    "\n",
    "n = np.shape(A)[0] # number of rows and columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-insurance",
   "metadata": {},
   "source": [
    "# Strictly diagonally dominant\n",
    "\n",
    "As a first step, we want to put the matrix $A$ in a strictly diagonally dominant form (if possible). A matrix \\textbf{M} is strictly diagonally dominant if \n",
    "\n",
    "\\begin{equation*} \n",
    "\\left|\\bf{M}\\right|_{ii} > \\sum_{i \\neq j} \\left|\\bf{M}\\right|_{ij}\n",
    "\\end{equation*} \\\\\n",
    "\n",
    "In order to check if the matrix $A$ is strictly diagonally dominant (SDD), a function is created. The function takes as inputs the matrix $A$ and the vector $b$. The function switches the rows of the input matrix and checks if the matrix with switched rows is SDD. When it finds a combination of rows that makes the matrix SDD, it returns the matrix with this combination of rows and the corresponding vector. If none of the combinations makes the matrix SDD, the input matrix and vector are returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amended-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_SDD(A, b):\n",
    "    check = False\n",
    "    n = np.shape(A)[0] # number of rows in matrix A\n",
    "    perm_list = list(itertools.permutations(np.arange(n)))\n",
    "    for perm in perm_list:                            \n",
    "        mat = A[perm,:] # matrix with switched rows\n",
    "        \n",
    "        # Check if the matrix is SDD\n",
    "        for y in range(n):\n",
    "            my_sum = 0\n",
    "            for z in range(n):\n",
    "                if y == z:\n",
    "                    my_sum += np.abs(mat[y, z]) # add when on diagonal\n",
    "                else:\n",
    "                    my_sum -= np.abs(mat[y, z]) # substract if not on diagonal\n",
    "            if my_sum <= 0:\n",
    "                check = False\n",
    "                break # avoid unnecessary computation if current mat is not SDD\n",
    "            else: \n",
    "                check = True\n",
    "        \n",
    "        # If matrix is SDD, return the new matrix with switched rows\n",
    "        # and corresponding vector\n",
    "        if check == True:\n",
    "            vec = [x for y, x in sorted(zip(perm, b))] # switch rows of the vector\n",
    "            print('The returned matrix is strictly diagonally dominant. \\n')\n",
    "            print('The returned matrix is \\n')\n",
    "            print(mat)\n",
    "            print('\\n The returned vector is \\n')\n",
    "            print(vec)\n",
    "            return mat, vec\n",
    "   \n",
    "    # If matrix is not SDD, return the original matrix and vector\n",
    "    print('The input matrix cannot be put in striclty diagonally dominant form.')\n",
    "    print('The original matrix and vector are returned.')\n",
    "    return A, b  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-blues",
   "metadata": {},
   "source": [
    "We now check if the matrix $A$ can be put in SDD form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eligible-research",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The returned matrix is strictly diagonally dominant. \n",
      "\n",
      "The returned matrix is \n",
      "\n",
      "[[10. -1.  2.  0.]\n",
      " [-1. 11. -1.  3.]\n",
      " [ 2. -1. 10. -1.]\n",
      " [ 0.  3. -1.  8.]]\n",
      "\n",
      " The returned vector is \n",
      "\n",
      "[6.0, 25.0, -11.0, 15.0]\n"
     ]
    }
   ],
   "source": [
    "A, b = is_SDD(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-basement",
   "metadata": {},
   "source": [
    "Now that the matrix $A$ is in strictly diagonally dominant form, we are going to solve the system $Ax = b$ for $x$ using different methods. \n",
    "\n",
    "# LU Decomposition\n",
    "\n",
    "## Doolittle's method \n",
    "\n",
    "\n",
    "The first step is to decompose the matrix $A$ into a lower triangular matrix, $L$, and an upper triangular matrix, $U$ such that $A = LU$. With Doolittle's method, the matrix $L$ is constructed such that $L_{ii} = 1 \\,\\, \\forall \\,\\,1 \\leq i \\leq n$.\n",
    "\n",
    "We now decompose the matrix $A$ into $L$ and $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "advanced-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix L is \n",
      "\n",
      "L = [[ 1.          0.          0.          0.        ]\n",
      "     [-0.1         1.          0.          0.        ]\n",
      "     [ 0.2        -0.0733945   1.          0.        ]\n",
      "     [ 0.          0.27522936 -0.08173077  1.        ]]\n",
      "\n",
      " The matrix U is \n",
      "\n",
      "U = [[10.         -1.          2.          0.        ]\n",
      "     [ 0.         10.9        -0.8         3.        ]\n",
      "     [ 0.          0.          9.5412844  -0.77981651]\n",
      "     [ 0.          0.          0.          7.11057692]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the matrices \n",
    "L = np.zeros((n, n))\n",
    "U = np.zeros((n, n))\n",
    "\n",
    "# LU decomposition\n",
    "for i in range(n):\n",
    "    # Upper triangular matrix\n",
    "    for k in range(i, n):\n",
    "        my_sum = 0\n",
    "        for j in range(i):\n",
    "            my_sum += L[i, j] * U[j, k]\n",
    "            \n",
    "        U[i, k] = A[i, k] - my_sum\n",
    "    \n",
    "    # Lower triangular matrix\n",
    "    for k in range(i, n):\n",
    "        if i == k:\n",
    "            L[i, k] = 1 # 1 on diagonal\n",
    "        else:\n",
    "            my_sum = 0\n",
    "            for j in range(i):\n",
    "                my_sum += L[k, j] * U[j, i]\n",
    "                \n",
    "            L[k, i] = (A[k, i] - my_sum) / U[i, i]\n",
    "\n",
    "print('The matrix L is \\n')\n",
    "print('L =', np.array2string(L, prefix='L = '))\n",
    "print('\\n The matrix U is \\n')\n",
    "print('U =', np.array2string(U, prefix='U = '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-vertical",
   "metadata": {},
   "source": [
    "A quick check shows that $A = LU$ is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "urban-court",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LU = [[10. -1.  2.  0.]\n",
      "      [-1. 11. -1.  3.]\n",
      "      [ 2. -1. 10. -1.]\n",
      "      [ 0.  3. -1.  8.]] \n",
      "\n",
      " A = [[10. -1.  2.  0.]\n",
      "      [-1. 11. -1.  3.]\n",
      "      [ 2. -1. 10. -1.]\n",
      "      [ 0.  3. -1.  8.]]\n"
     ]
    }
   ],
   "source": [
    "print('LU =', np.array2string(np.dot(L,U), prefix='LU = '), '\\n\\n','A =', np.array2string(A, prefix='A =  '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-monday",
   "metadata": {},
   "source": [
    "The system $Ax = b$ can be written as $Ax = (LU)x = L(Ux) = b$. Introducing the vector $z = Ux$, we have $Lz = b$. \n",
    "\n",
    "We now solve for $z$ using forward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "growing-organizer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector z is \n",
      "\n",
      "z = [  6.          25.6        -10.32110092   7.11057692]\n"
     ]
    }
   ],
   "source": [
    "# Initialize array for the vector z\n",
    "z = np.zeros(n)\n",
    "z[0] = b[0]\n",
    "\n",
    "# Solve Lz = b for z using forward substitution\n",
    "for i in range(1, n):\n",
    "    my_sum = 0\n",
    "    for j in range(i):\n",
    "        my_sum += L[i, j] * z[j]\n",
    "    z[i] = b[i] - my_sum\n",
    "\n",
    "print('The vector z is \\n')\n",
    "print('z =', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-cassette",
   "metadata": {},
   "source": [
    "Again, a quick check shows that $Lz = b$ is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charitable-strand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lz = [  6.  25. -11.  15.] \n",
      "\n",
      " b = [6.0, 25.0, -11.0, 15.0]\n"
     ]
    }
   ],
   "source": [
    "print('Lz =', np.dot(L, z), '\\n\\n', 'b =', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-boutique",
   "metadata": {},
   "source": [
    "Now that $z$ is known, the last step is to solve $Ux = z$ for $x$ using backward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ready-produce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector x is \n",
      "\n",
      "x = [ 1.  2. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize array for the vector x\n",
    "x = np.zeros(n)\n",
    "x[n-1] = z[n-1]/U[n-1, n-1]\n",
    "\n",
    "# Solve Ux = z for x using backward substitution\n",
    "for i in range(n-2, -1, -1):\n",
    "    my_sum = 0\n",
    "    for j in range(n-1, i, -1):\n",
    "        my_sum = my_sum + U[i, j] * x[j]\n",
    "    x[i] = (z[i] - my_sum) / U[i, i]\n",
    "\n",
    "print('The vector x is \\n')\n",
    "print('x =', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-austin",
   "metadata": {},
   "source": [
    "A quick check shows that $Ax = b$ is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sustainable-chair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ax = [  6.  25. -11.  15.] \n",
      "\n",
      " b = [6.0, 25.0, -11.0, 15.0] \n",
      "\n",
      " [ True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print('Ax =', np.dot(A, x), '\\n\\n', 'b =', b, '\\n\\n', np.dot(A, x)==b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-marketing",
   "metadata": {},
   "source": [
    "The last line shows that Doolittle's method is very accurate. The matrix vector product $Ax$ returns exactly the value of $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-syndicate",
   "metadata": {},
   "source": [
    "## Crout's method\n",
    "\n",
    "Crout's method is very similar to Doolittle's method. The difference is that the LU decomposition is done such that there is a diagonal of ones in the upper triangular matrix whereas the diagonal of ones is in the lower triangular matrix with Doolittle's method. Hence with Crout's method, $U_{ii} = 1 \\,\\, \\forall \\,\\, 1 \\leq i \\leq n$.\n",
    "\n",
    "We now decompose $A$ into $L$ and $U$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dynamic-costs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix L is \n",
      "\n",
      "L = [[10.          0.          0.          0.        ]\n",
      "     [-1.         10.9         0.          0.        ]\n",
      "     [ 2.         -0.8         9.5412844   0.        ]\n",
      "     [ 0.          3.         -0.77981651  7.11057692]]\n",
      "\n",
      " The matrix U is \n",
      "\n",
      "U = [[ 1.         -0.1         0.2         0.        ]\n",
      "     [ 0.          1.         -0.0733945   0.27522936]\n",
      "     [ 0.          0.          1.         -0.08173077]\n",
      "     [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the matrices\n",
    "L = np.zeros((n, n))\n",
    "U = np.zeros((n, n))\n",
    "\n",
    "# LU decomposition\n",
    "for i in range(0, n):\n",
    "    # Lower triangular matrix\n",
    "    for k in range(i, n):\n",
    "        my_sum = 0\n",
    "        for j in range(0, i):\n",
    "            my_sum += L[i, j] * U[j, k] \n",
    "        L[k, i] = A[i, k] - my_sum\n",
    "    \n",
    "    # Upper triangular matrix\n",
    "    for k in range(i, n):\n",
    "        if i == k:\n",
    "            U[i, k] = 1 # 1 on the diagonal\n",
    "        else:\n",
    "            my_sum = 0\n",
    "            for j in range(0, i):\n",
    "                my_sum += L[i, j] * U[j, k] \n",
    "            U[i, k] = (A[i, k] - my_sum) / L[i, i]\n",
    "            \n",
    "print('The matrix L is \\n')\n",
    "print('L =', np.array2string(L, prefix='L = '))\n",
    "print('\\n The matrix U is \\n')\n",
    "print('U =', np.array2string(U, prefix='U = '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-blackberry",
   "metadata": {},
   "source": [
    "A quick check shows that $A = LU$ is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "plastic-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LU = [[10. -1.  2.  0.]\n",
      "      [-1. 11. -1.  3.]\n",
      "      [ 2. -1. 10. -1.]\n",
      "      [ 0.  3. -1.  8.]] \n",
      "\n",
      " A = [[10. -1.  2.  0.]\n",
      "      [-1. 11. -1.  3.]\n",
      "      [ 2. -1. 10. -1.]\n",
      "      [ 0.  3. -1.  8.]]\n"
     ]
    }
   ],
   "source": [
    "print('LU =', np.array2string(np.dot(L,U), prefix='LU = '), '\\n\\n','A =', np.array2string(A, prefix='A =  '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-martin",
   "metadata": {},
   "source": [
    "The system $Ax = b$ can be written as $Ax = (LU)x = L(Ux) = b$. Introducing the vector $z = Ux$, we have $Lz = b$. \n",
    "\n",
    "We now solve for $z$ using forward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "particular-mystery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector z is \n",
      "\n",
      "z = [ 0.6         2.34862385 -1.08173077  1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Initialize array for the vector z\n",
    "z = np.zeros(n)\n",
    "z[0] = b[0]/L[0, 0]\n",
    "\n",
    "# Solve Lz = b using forward substitution\n",
    "for i in range(1, n):\n",
    "    my_sum = 0\n",
    "    for j in range(i):\n",
    "        my_sum += L[i, j] * z[j]\n",
    "    z[i] = (b[i] - my_sum) / L[i, i]\n",
    "\n",
    "print('The vector z is \\n')\n",
    "print('z =', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-saint",
   "metadata": {},
   "source": [
    "Again, a quick check shows that $Lz = b$ is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "municipal-heather",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lz = [  6.  25. -11.  15.] \n",
      "\n",
      " b = [6.0, 25.0, -11.0, 15.0]\n"
     ]
    }
   ],
   "source": [
    "print('Lz =', np.dot(L, z), '\\n\\n', 'b =', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-bailey",
   "metadata": {},
   "source": [
    "Now that $z$ is known, the last step is to solve $Ux = z$ for $x$ using backward substitution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fatal-reconstruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector x is \n",
      "\n",
      "x = [ 1.  2. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize array for the vector x\n",
    "x = np.zeros(n)\n",
    "x[n-1] = z[n-1]\n",
    "\n",
    "# Solve Ux = z for x using backward substitution\n",
    "for i in range(n-2, -1, -1):\n",
    "    my_sum = 0\n",
    "    for j in range(n-1, i, -1):\n",
    "        my_sum = my_sum + U[i, j] * x[j]\n",
    "    x[i] = (z[i] - my_sum)\n",
    "    \n",
    "print('The vector x is \\n')\n",
    "print('x =', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-passenger",
   "metadata": {},
   "source": [
    "As expected, Crout's method yields the same solution as Doolittle's method. A quick check shows that $Ax = b$ is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "incoming-internet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ax = [  6.  25. -11.  15.] \n",
      "\n",
      " b = [6.0, 25.0, -11.0, 15.0] \n",
      "\n",
      " [ True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print('Ax =', np.dot(A, x), '\\n\\n', 'b =', b, '\\n\\n', np.dot(A, x)==b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-budapest",
   "metadata": {},
   "source": [
    "The last line shows that Crout's method is very accurate as is Doolittle's method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-stretch",
   "metadata": {},
   "source": [
    "# Gauss-Seidel\n",
    "\n",
    "The Gauss-Seidel method is an iterative technique. It requires an initial guess, $x^{(0)}$, for the vector $x$. Then, at each iteration, the elements of the vector $x^{(k)}$ are updated such that\n",
    "\\begin{equation*}\n",
    "x^{(k + 1)}_i = \\frac{1}{a_{ii}} \\left[b_i - \\sum^{i-1}_{j = 1} \\left( a_{ij} x_j^{(k + 1)} \\right) - \\sum^{n}_{j = i + 1} \\left( a_{ij} x^{(k)}_j \\right) \\right]\n",
    "\\end{equation*}\n",
    "\n",
    "where $k$ is the iteration number and $i = 1,...,n$.\n",
    "\n",
    "Here, we are going to solve the system starting with initial guess $x^{(0)} = (0, 0, 0, 0)$ and then $x^{(0)} = (1, 1, 1, 1)$. In order to easily solve the system with both starting points, we are going to implement the Gauss-Seidel method as a function. The function takes as input the matrix $A$, the vector $b$, the initial guess $x^{(0)}$ and the tolerance level at which convergence is achieved, $\\epsilon$. The algorithm updates the vector $x$ until convergence is reached. The criterion for convergence is \n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\left| \\left| x^{(k + 1)} - x^{(k)} \\right| \\right|_{\\infty}}{\\left|\\left| x^{(k)} \\right| \\right|_{\\infty}} < \\epsilon\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\Vert \\,{\\gamma}\\, \\rVert _{\\infty} $ is the $l_{\\infty}$ norm of the vector $\\gamma$.\n",
    "\n",
    "When convergence is reached, the function returns the vector $x$ and the number of iterations required to reach convergence. At each iteration, the function also prints the vector $x^{(k)}$ along with the $l_{\\infty}$ norm criterion. Printing can be turned off by setting the optional argument print_on to False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cognitive-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gauss_Seidel(A, b, guess, tol, print_on=True):\n",
    "    l_inf = tol + 1\n",
    "    x = guess\n",
    "    count = 0\n",
    "    while l_inf > tol:\n",
    "        y = x.copy() # keep value of x at previous iterate\n",
    "        count += 1\n",
    "        for i in range(n):\n",
    "            my_sum = 0\n",
    "            for j in range(n):\n",
    "                if j != i:\n",
    "                    my_sum += A[i, j]*x[j]\n",
    "                    \n",
    "            x[i] = (b[i]-my_sum)/A[i, i]\n",
    "        \n",
    "        # norm criterion\n",
    "        if max(np.abs(y)) != 0: # Avoid division by zero   \n",
    "            l_inf = max(np.abs(y - x))/max(np.abs(y)) # l_{\\infty} norm criterion\n",
    "        \n",
    "        if print_on: # If print_on is True, print output at each iteration\n",
    "            print('Iteration ' + str(count) + ':')\n",
    "            print('x =', x)\n",
    "            if max(np.abs(y)) != 0:\n",
    "                print('l_inf = ', l_inf, '\\n') \n",
    "            else:\n",
    "                print('l_inf = N/A - Division by zero \\n')\n",
    "        \n",
    "    return x, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-squad",
   "metadata": {},
   "source": [
    "We define the tolerance level for convergence as $\\epsilon = 0.0001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bronze-amendment",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.0001 # epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-exclusion",
   "metadata": {},
   "source": [
    "We first solve the system with initial guess $x^{(0)} = (0, 0, 0, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "joint-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "x = [ 0.6         2.32727273 -0.98727273  0.87886364]\n",
      "l_inf = N/A - Division by zero \n",
      "\n",
      "Iteration 2:\n",
      "x = [ 1.03018182  2.03693802 -1.0144562   0.98434122]\n",
      "l_inf =  0.18484375000000003 \n",
      "\n",
      "Iteration 3:\n",
      "x = [ 1.00658504  2.00355502 -1.00252738  0.99835095]\n",
      "l_inf =  0.016388814658793216 \n",
      "\n",
      "Iteration 4:\n",
      "x = [ 1.00086098  2.00029825 -1.00030728  0.99984975]\n",
      "l_inf =  0.002856953090344185 \n",
      "\n",
      "Iteration 5:\n",
      "x = [ 1.00009128  2.00002134 -1.00003115  0.9999881 ]\n",
      "l_inf =  0.0003847917873479008 \n",
      "\n",
      "Iteration 6:\n",
      "x = [ 1.00000836  2.00000117 -1.00000275  0.99999922]\n",
      "l_inf =  4.1457869928006095e-05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "x = np.zeros(n)\n",
    "\n",
    "# Solve the system\n",
    "x, count = Gauss_Seidel(A, b, x, tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-processing",
   "metadata": {},
   "source": [
    "With the initial guess $x^{(0)} = (0, 0, 0, 0)$, convergence is reached at the sixth iteration. We can calculate the difference with the actual solution which is $x = (1, 2, -1, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cordless-victor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.36366133e-06  1.17333627e-06 -2.74507268e-06 -7.83135185e-07]\n"
     ]
    }
   ],
   "source": [
    "print(x - [1, 2, -1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cognitive-booth",
   "metadata": {},
   "source": [
    "We now solve the system with initial guess $x^{(0)} = (1, 1, 1, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ideal-accident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "x = [ 0.5         2.13636364 -0.88636364  0.96306818]\n",
      "l_inf =  1.8863636363636362 \n",
      "\n",
      "Iteration 2:\n",
      "x = [ 0.99090909  2.01957645 -0.99991736  0.99266916]\n",
      "l_inf =  0.22978723404255322 \n",
      "\n",
      "Iteration 3:\n",
      "x = [ 1.00194112  2.0021833  -1.00090298  0.99906839]\n",
      "l_inf =  0.008612275598771235 \n",
      "\n",
      "Iteration 4:\n",
      "x = [ 1.00039893  2.00020825 -1.00015212  0.99990289]\n",
      "l_inf =  0.0009864457246365598 \n",
      "\n",
      "Iteration 5:\n",
      "x = [ 1.00005125  2.00001731 -1.00001823  0.99999123]\n",
      "l_inf =  0.00017381979942646743 \n",
      "\n",
      "Iteration 6:\n",
      "x = [ 1.00000538  2.00000122 -1.00000183  0.99999931]\n",
      "l_inf =  2.293582118326794e-05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "x = np.ones(n)\n",
    "\n",
    "# Solve the system\n",
    "x, count = Gauss_Seidel(A, b, x, tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-helicopter",
   "metadata": {},
   "source": [
    "With the initial point $x^{(0)} = (1, 1, 1, 1)$, convergence is reached at the sixth iteration. It is the same number of iterations as for the initial point $x^{(0)} = (0, 0, 0, 0)$. We can also calculate the difference with the actual solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "known-beverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.37731357e-06  1.22386894e-06 -1.83023074e-06 -6.87729695e-07]\n"
     ]
    }
   ],
   "source": [
    "print(x - [1, 2, -1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-choir",
   "metadata": {},
   "source": [
    "Even though both methods converge within the same number of iterations, the difference between the computed vector and the actual solution is smaller with the initial point $x^{(0)} = (1, 1, 1, 1)$. This suggests that convergence could have been reached faster with this starting point if another tolerance level was chosen.\n",
    "\n",
    "The returned vector is very close to the actual vector $x$ but they are not exactly equal. Decreasing the tolerance level would increase accuracy. However, the Gauss-Seidel method is less accurate than the Doolittle's and Crout's methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-dallas",
   "metadata": {},
   "source": [
    "# Successive-Over-Relaxation\n",
    "\n",
    "Successive-Over-Relaxation (SOR) is an iterative method similar to the Gauss-Seidel method. The difference is that an acceleration factor, $\\omega$, is used to accelerate convergence. At each iteration, the elements of $x^{(k)}$ are updated such that\n",
    "\n",
    "\\begin{equation*}\n",
    "x^{(k + 1)}_i = (1 - \\omega)x_i^{(k)} + \\frac{\\omega}{a_{ii}} \\left[b_i - \\sum^{i-1}_{j = 1} \\left( a_{ij} x_j^{(k + 1)} \\right) - \\sum^{n}_{j = i + 1} \\left( a_{ij} x^{(k)}_j \\right) \\right]\n",
    "\\end{equation*}\n",
    "\n",
    "The function for SOR is very similar to the one used for the Gauss-Seidel method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "increasing-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOR(A, b, guess, omega, tol, print_on=True):\n",
    "    l_inf = tol + 1\n",
    "    x = guess\n",
    "    count = 0\n",
    "    while l_inf > tol:\n",
    "        y = x.copy() # keep value of x at previous iterate as y\n",
    "        count += 1\n",
    "        for i in range(n):\n",
    "            my_sum = 0\n",
    "            for j in range(n):\n",
    "                if j != i:\n",
    "                    my_sum += A[i, j]*x[j]\n",
    "                    \n",
    "            x[i] = (1-omega)*y[i] + omega*(b[i]-my_sum)/A[i, i]\n",
    "        \n",
    "        # norm criterion\n",
    "        if max(np.abs(y)) != 0: # Avoid division by zero   \n",
    "            l_inf = max(np.abs(y - x))/max(np.abs(y)) # l_{\\infty} norm criterion\n",
    "        \n",
    "        if print_on: # If print_on is true, print output at each iterate\n",
    "            print('Iteration ' + str(count) + ':')\n",
    "            print('x =', x)\n",
    "            if max(np.abs(y)) != 0:\n",
    "                print('l_inf = ', l_inf, '\\n') \n",
    "            else:\n",
    "                print('l_inf = N/A - Division by zero \\n')\n",
    "    \n",
    "    return x, count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-publicity",
   "metadata": {},
   "source": [
    "We define the acceleration factor as $\\omega = 1.1$ and the tolerance level as $\\epsilon = 0.0001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "waiting-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega = 1.1\n",
    "tol = 0.0001 # epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-monitor",
   "metadata": {},
   "source": [
    "We now solve the system with initial guess $x^{(0)} = (0, 0, 0, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "promotional-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1:\n",
      "x = [ 0.66        2.566      -1.07294     0.85649575]\n",
      "l_inf = N/A - Division by zero \n",
      "\n",
      "Iteration 2:\n",
      "x = [ 1.1123068   1.99038796 -1.03425629  1.01360515]\n",
      "l_inf =  0.22432269875292288 \n",
      "\n",
      "Iteration 3:\n",
      "x = [ 0.99524838  1.99297887 -0.99480477  1.00225005]\n",
      "l_inf =  0.05881186187694755 \n",
      "\n",
      "Iteration 4:\n",
      "x = [ 0.99855989  2.00040261 -0.99991091  0.99962117]\n",
      "l_inf =  0.0037249485598974 \n",
      "\n",
      "Iteration 5:\n",
      "x = [ 1.0001687   2.00009917 -1.00007679  0.99998642]\n",
      "l_inf =  0.0008042432684686864 \n",
      "\n",
      "Iteration 6:\n",
      "x = [ 1.00001093  1.99998757 -0.99999759  1.00000682]\n",
      "l_inf =  7.887918876179545e-05 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initial guess\n",
    "x = np.zeros(n)\n",
    "\n",
    "# Solve the system\n",
    "x, count = SOR(A, b, x, omega, tol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-wonder",
   "metadata": {},
   "source": [
    "With the initial starting point $x^{(0)} = (0, 0, 0, 0)$, convergence is reached in six iterations. This is similar to the results for Gauss-Seidel method. Again, we calculate the difference between the computed vector and the actual solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "expected-johnson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.09315505e-05 -1.24277278e-05  2.41263573e-06  6.81632696e-06]\n"
     ]
    }
   ],
   "source": [
    "print(x - [1, 2, -1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-guyana",
   "metadata": {},
   "source": [
    "The difference is bigger than for the Gauss-Seidel method (with both starting points). This suggests that using the acceleration factor $\\omega = 1.1$ does not accelerate convergence and even makes convergence slower.\n",
    "\n",
    "As with the Gauss-Seidel method, the returned vector is close to the true vector $x$ but not equal. Decreasing the tolerance level would increase accuracy. However, iterative methods are less accurate than Doolittle's or Crout's methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-retreat",
   "metadata": {},
   "source": [
    "# Computational efficiency comparison\n",
    "\n",
    "In order to assess if a method converges faster, we are going to compare the number of iterations required to converge for various tolerance levels. The considered range for the tolerance level is $[10^{-1}, 10^{-10}]$ with values of $\\epsilon$ in the form $10^{-m}, m \\in \\mathbb{N}$.\n",
    "\n",
    "First, we use an initial guess $x^{(0)} = (0, 0, 0, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "married-catholic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon =  0.1 \n",
      "\n",
      "Iterations GS:   3 \n",
      "\n",
      "Iterations SOR:  3 \n",
      "\n",
      "\n",
      "epsilon =  0.01 \n",
      "\n",
      "Iterations GS:   4 \n",
      "\n",
      "Iterations SOR:  4 \n",
      "\n",
      "\n",
      "epsilon =  0.001 \n",
      "\n",
      "Iterations GS:   5 \n",
      "\n",
      "Iterations SOR:  5 \n",
      "\n",
      "\n",
      "epsilon =  0.0001 \n",
      "\n",
      "Iterations GS:   6 \n",
      "\n",
      "Iterations SOR:  6 \n",
      "\n",
      "\n",
      "epsilon =  1e-05 \n",
      "\n",
      "Iterations GS:   7 \n",
      "\n",
      "Iterations SOR:  7 \n",
      "\n",
      "\n",
      "epsilon =  1e-06 \n",
      "\n",
      "Iterations GS:   8 \n",
      "\n",
      "Iterations SOR:  9 \n",
      "\n",
      "\n",
      "epsilon =  1e-07 \n",
      "\n",
      "Iterations GS:   9 \n",
      "\n",
      "Iterations SOR:  10 \n",
      "\n",
      "\n",
      "epsilon =  1e-08 \n",
      "\n",
      "Iterations GS:   10 \n",
      "\n",
      "Iterations SOR:  11 \n",
      "\n",
      "\n",
      "epsilon =  1e-09 \n",
      "\n",
      "Iterations GS:   11 \n",
      "\n",
      "Iterations SOR:  12 \n",
      "\n",
      "\n",
      "epsilon =  1e-10 \n",
      "\n",
      "Iterations GS:   11 \n",
      "\n",
      "Iterations SOR:  13 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = np.zeros(n) # Initialize x at each step\n",
    "    tol = 10**(-(i+1))\n",
    "    count_GS = Gauss_Seidel(A, b, x, tol, print_on=False)[1]\n",
    "    x = np.zeros(n) # Initialize x for the SOR method\n",
    "    count_SOR = SOR(A, b, x, omega, tol, print_on=False)[1]\n",
    "\n",
    "    print('epsilon = ', tol, '\\n')\n",
    "    print('Iterations GS:  ', count_GS, '\\n')\n",
    "    print('Iterations SOR: ', count_SOR, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-residence",
   "metadata": {},
   "source": [
    "With the initial vector $x^{(0)} = (0, 0, 0, 0)$, both the Gauss-Seidel and SOR methods converge within the same number of iterations for values of $\\epsilon$ between $10^{-5}$ and $10^{-1}$. With lower values of $\\epsilon$, the SOR method is slower (it needs more iterations to converge).\n",
    "\n",
    "We now repeat the process with the initial guess $x^{(0)} = (1, 1, 1, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "quick-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon =  0.1 \n",
      "\n",
      "Iterations GS:   3 \n",
      "\n",
      "Iterations SOR:  3 \n",
      "\n",
      "\n",
      "epsilon =  0.01 \n",
      "\n",
      "Iterations GS:   3 \n",
      "\n",
      "Iterations SOR:  4 \n",
      "\n",
      "\n",
      "epsilon =  0.001 \n",
      "\n",
      "Iterations GS:   4 \n",
      "\n",
      "Iterations SOR:  5 \n",
      "\n",
      "\n",
      "epsilon =  0.0001 \n",
      "\n",
      "Iterations GS:   6 \n",
      "\n",
      "Iterations SOR:  6 \n",
      "\n",
      "\n",
      "epsilon =  1e-05 \n",
      "\n",
      "Iterations GS:   7 \n",
      "\n",
      "Iterations SOR:  7 \n",
      "\n",
      "\n",
      "epsilon =  1e-06 \n",
      "\n",
      "Iterations GS:   8 \n",
      "\n",
      "Iterations SOR:  8 \n",
      "\n",
      "\n",
      "epsilon =  1e-07 \n",
      "\n",
      "Iterations GS:   9 \n",
      "\n",
      "Iterations SOR:  9 \n",
      "\n",
      "\n",
      "epsilon =  1e-08 \n",
      "\n",
      "Iterations GS:   10 \n",
      "\n",
      "Iterations SOR:  11 \n",
      "\n",
      "\n",
      "epsilon =  1e-09 \n",
      "\n",
      "Iterations GS:   11 \n",
      "\n",
      "Iterations SOR:  12 \n",
      "\n",
      "\n",
      "epsilon =  1e-10 \n",
      "\n",
      "Iterations GS:   11 \n",
      "\n",
      "Iterations SOR:  13 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = np.ones(n) # Initialize x at each step\n",
    "    tol = 10**(-(i+1))\n",
    "    count_GS = Gauss_Seidel(A, b, x, tol, print_on=False)[1]\n",
    "    x = np.ones(n) # Initialize x for the SOR method\n",
    "    count_SOR = SOR(A, b, x, omega, tol, print_on=False)[1]\n",
    "\n",
    "    print('epsilon = ', tol, '\\n')\n",
    "    print('Iterations GS:  ', count_GS, '\\n')\n",
    "    print('Iterations SOR: ', count_SOR, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moderate-thumbnail",
   "metadata": {},
   "source": [
    "With the initial guess $x^{(0)} = (1, 1, 1, 1)$, the Gauss-Seidel method converges faster for values of epsilon lower than $10^{-8}$ as well as for values between $10^{-2}$ and $10^{-3}$. For other values of $\\epsilon$, both methods converge in the same number of iterations. It also appears that the Gauss-Seidel method converges faster with the initial guess $x^{(0)} = (1, 1, 1, 1)$ than with $x^{(0)} = (0, 0, 0, 0)$ when $\\epsilon$ is between $10^{-2}$ and $10^{-3}$. For other values of $\\epsilon$, the Gauss-Seidel method converges within the same number of iterations with both initial vectors.\n",
    "\n",
    "Overall, given the problem, the Gauss-Seidel method with initial guess $x^{(0)} = (1, 1, 1, 1)$ seems to converge faster than other iterative methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-malaysia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "email": "robin.guilliou@gmail.com",
    "name": "Robin Guilliou"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
